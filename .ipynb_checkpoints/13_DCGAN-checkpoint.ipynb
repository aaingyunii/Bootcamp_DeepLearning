{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DiNH4UpHmLNt"
   },
   "source": [
    "# Down sampling과 Up sampling\n",
    "- Down sampling\n",
    "    - Convolution을 진행하면서 입력 이미지의 크기를 줄여가는 것\n",
    "    - convolution의 stride나 Pooling layer를 이용해 줄인다.\n",
    "- Up sampling\n",
    "    - Convolution을 진행하면서 입력 이미지의 크기를 늘려가는 것\n",
    "    - 보통 convolution의 stride나 Pooling layer를 이용해 줄여진 이미지를 다시 원래 크기로 복원 시킬때 많이 사용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zoi8LkNXmLNu"
   },
   "source": [
    "# UpSampling\n",
    "- tensorflow.keras.layers.UpSampling2D 사용.\n",
    "- 단순히 늘린다. \n",
    "    - 크기를 늘리는 resizing을 한 뒤 빈 공간을 채운다.\n",
    "- UpSampling2D로 입력 이미지의 사이즈를 늘린 뒤 Conv2D를 연결해서 학습이 되도록 한다.\n",
    "- 하이퍼파라미터\n",
    "    - size=(2,2) : 입력을 몇배로 크게 만들지 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26723,
     "status": "ok",
     "timestamp": 1678785131219,
     "user": {
      "displayName": "encore엔코아",
      "userId": "03488190351334320755"
     },
     "user_tz": -540
    },
    "id": "RzPH-DAaY6oo",
    "outputId": "4cf6a331-2463-45fb-b567-1584c9feefe5"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T07:41:34.293584Z",
     "start_time": "2023-03-14T07:41:29.997241Z"
    },
    "executionInfo": {
     "elapsed": 3977,
     "status": "ok",
     "timestamp": 1678785102729,
     "user": {
      "displayName": "encore엔코아",
      "userId": "03488190351334320755"
     },
     "user_tz": -540
    },
    "id": "-TQhHt8qmLNv"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T07:42:06.938620Z",
     "start_time": "2023-03-14T07:42:06.924280Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 958,
     "status": "ok",
     "timestamp": 1604979999342,
     "user": {
      "displayName": "Sunghwan KIM",
      "photoUrl": "",
      "userId": "06010856989212311727"
     },
     "user_tz": -540
    },
    "id": "ijeDWJyAmLNz",
    "outputId": "095d343b-dd91-4f38-9c3b-9553b9e2275a"
   },
   "outputs": [],
   "source": [
    "X = np.arange(1, 5).reshape(1, 2, 2, 1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T07:46:51.946179Z",
     "start_time": "2023-03-14T07:46:51.917555Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 950,
     "status": "ok",
     "timestamp": 1604979999344,
     "user": {
      "displayName": "Sunghwan KIM",
      "photoUrl": "",
      "userId": "06010856989212311727"
     },
     "user_tz": -540
    },
    "id": "r4lMMqz7mLN1",
    "outputId": "d63e2700-3f29-44e5-a6f9-e94845a363c5"
   },
   "outputs": [],
   "source": [
    "# interpolation='nearest' : default, 'bilinear' 두가지 방식 제공\n",
    "model = keras.Sequential()\n",
    "# model.add(layers.UpSampling2D(size=2, input_shape=(2,2,1)))\n",
    "model.add(layers.UpSampling2D(size=5, interpolation='bilinear', input_shape=(2,2,1)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T07:47:17.065893Z",
     "start_time": "2023-03-14T07:47:16.947741Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1283,
     "status": "ok",
     "timestamp": 1604979999685,
     "user": {
      "displayName": "Sunghwan KIM",
      "photoUrl": "",
      "userId": "06010856989212311727"
     },
     "user_tz": -540
    },
    "id": "y6icxoq_mLN5",
    "outputId": "457e8487-8790-4a8e-96d0-2e2e0a09675b"
   },
   "outputs": [],
   "source": [
    "X_up = model.predict(X)\n",
    "X_up.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T07:47:17.658978Z",
     "start_time": "2023-03-14T07:47:17.637082Z"
    },
    "id": "tFKtNs0WYyss",
    "outputId": "90ba3fa7-d4a9-40d5-8beb-0fd1fd265fff"
   },
   "outputs": [],
   "source": [
    "X_up.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a60M-JIYmLOA"
   },
   "source": [
    "##  Transpose Convolution\n",
    "- tensorflow.keras.layers.Conv2DTranspose 를 이용\n",
    "- parameter가 있는 Filter를 이용해 입력 이미지의 사이즈를 늘린다.\n",
    "    - convolution 계산을 역으로 하는 방식을 사용한다.\n",
    "- padding을 same으로 하고 strides로 크기를 정한다.\n",
    "    - size가 strides로 지정한 배수 만큼 늘어난다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T07:49:58.408989Z",
     "start_time": "2023-03-14T07:49:58.230227Z"
    },
    "id": "6VWTUrPimLOB"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Conv2DTranspose(kernel_size=3, filters=12, strides=2, padding='same', input_shape=(2,2,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T07:50:06.737743Z",
     "start_time": "2023-03-14T07:50:06.566093Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1260,
     "status": "ok",
     "timestamp": 1604979999687,
     "user": {
      "displayName": "Sunghwan KIM",
      "photoUrl": "",
      "userId": "06010856989212311727"
     },
     "user_tz": -540
    },
    "id": "vC9VPQAcmLOE",
    "outputId": "29d05fd8-daa1-406d-88d0-0a5020eebb22"
   },
   "outputs": [],
   "source": [
    "X_up2 = model.predict(X)\n",
    "X.shape, X_up2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T07:50:26.848850Z",
     "start_time": "2023-03-14T07:50:26.837455Z"
    },
    "id": "h2nIRKrHYyst",
    "outputId": "3e5ceb5d-de92-4865-8064-ba2cef30c079"
   },
   "outputs": [],
   "source": [
    "X_up2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XL8jpDrZmLOR"
   },
   "source": [
    "# DCGAN \n",
    "\n",
    "- Deep Convolutional Network + GAN\n",
    "- 처음 GAN 모델은 Dense Layer를 사용했는데 이것을 Convolution Layer로 변경함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lShdbs2xmLOR"
   },
   "source": [
    "## DCGAN의 안정적 학습을 위한 가이드라인\n",
    "1. Convolution 레이어에 Pooling Layer를 사용하지 않는다.\n",
    "2. 안정적 학습을 위해 BatchNormalization 사용.\n",
    "3. Fully Connected Layer (Dense) 를 사용하지 않는다. (Discriminator의 출력은 예외)\n",
    "4. Generator의 Hidden Layer에는 LeakyReLU activation을 사용하고 출력 Layer는 Tanh를 사용.\n",
    "5. Discriminator의 모든 Layer는 LeakyReLU activation을 사용한다. (Discriminator의 출력은 예외)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T08:15:54.086509Z",
     "start_time": "2023-03-14T08:15:54.080097Z"
    },
    "executionInfo": {
     "elapsed": 931,
     "status": "ok",
     "timestamp": 1678785148196,
     "user": {
      "displayName": "encore엔코아",
      "userId": "03488190351334320755"
     },
     "user_tz": -540
    },
    "id": "G4UjcYEXmLOS"
   },
   "outputs": [],
   "source": [
    "# 생성할 대상 학습 데이터셋: fashion mnist dataset => (28, 28, 1)\n",
    "img_shape = (28, 28, 1)  # 판별자의 input shape\n",
    "z_dim = 100  # 생성자에 입력할 잡음(Latent space/vector)  vector 크기  (100, ) --생성자---> (28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qfdQsaGwhN7C"
   },
   "source": [
    "# 생성자\n",
    "- 이미지 upsampling\n",
    "    - 7X7 => 14X14 => 28X28 로 키운다.\n",
    "    - Transpose Convolution 사용\n",
    "        - Conv2DTranspose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T08:18:59.720179Z",
     "start_time": "2023-03-14T08:18:59.700203Z"
    },
    "id": "iih6jz4WYysu",
    "outputId": "cac85d4f-e712-43a2-ffee-8faf4d91b570"
   },
   "outputs": [],
   "source": [
    "7*7*256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T08:29:52.961654Z",
     "start_time": "2023-03-14T08:29:52.939447Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1678785150539,
     "user": {
      "displayName": "encore엔코아",
      "userId": "03488190351334320755"
     },
     "user_tz": -540
    },
    "id": "5F_zptpJmLOa"
   },
   "outputs": [],
   "source": [
    "def create_generator(z_dim=100):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    model.add(layers.Dense(7*7*256, input_shape=(z_dim, )))\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "\n",
    "#     image size는 두배씩 늘리고 channel은 두배씩 줄인다.\n",
    "    # Convolution block : Conv2DTranspose -> BatchNormalization -> Activation(LeakyReLU)\n",
    "    model.add(layers.Conv2DTranspose(filters=128, kernel_size=3, strides=2, padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.01))\n",
    "\n",
    "    # 채널만 절반으로 줄임.\n",
    "    model.add(layers.Conv2DTranspose(filters=64, kernel_size=3, strides=1, padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    # size는 절반으로 늘림. 14 X 14 => 28 X 28, channle: 1 (grayscale)\n",
    "    model.add(layers.Conv2DTranspose(filters=1, kernel_size=3, strides=2, padding='same'))\n",
    "    model.add(layers.Activation(\"tanh\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hayk5OI0iiUl"
   },
   "source": [
    "# 판별자\n",
    "- 28 X 28 input => 14 X 14 => 7 X 7 => 3 X 3으로 절반씩 down sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T08:34:10.682632Z",
     "start_time": "2023-03-14T08:34:10.666470Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1678785152583,
     "user": {
      "displayName": "encore엔코아",
      "userId": "03488190351334320755"
     },
     "user_tz": -540
    },
    "id": "jVYQGgyOmLOk"
   },
   "outputs": [],
   "source": [
    "def create_discriminator(img_shape):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # pooling layer를 사용하지 않고 stride를 이용해서 size를 줄인다.\n",
    "    # size를 절반씩 줄여나간다. filter(channel)는 32->64->128 늘린다.\n",
    "    model.add(layers.Conv2D(filters=32, kernel_size=3, strides=2, padding='same',\n",
    "                            input_shape=img_shape))\n",
    "    model.add(layers.LeakyReLU(alpha=0.01))\n",
    "\n",
    "    model.add(layers.Conv2D(filters=64, kernel_size=3, strides=2,padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.01))\n",
    "\n",
    "    model.add(layers.Conv2D(filters=128, kernel_size=3, strides=2,padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.01))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))  # 출력: 이진분류 - 0:fake, 1:real\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NdYuBk6bq7BB"
   },
   "source": [
    "# GAN 모델\n",
    "- 생성자 + 판별자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T08:34:11.519925Z",
     "start_time": "2023-03-14T08:34:11.514824Z"
    },
    "executionInfo": {
     "elapsed": 607,
     "status": "ok",
     "timestamp": 1678785154599,
     "user": {
      "displayName": "encore엔코아",
      "userId": "03488190351334320755"
     },
     "user_tz": -540
    },
    "id": "t2wubdVRmLOp"
   },
   "outputs": [],
   "source": [
    "def create_gan(generator, discriminator):\n",
    "    model = keras.Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ixaYtCUemLOr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6XAVMlXArPNS"
   },
   "source": [
    "# 모델 생성 및 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T08:43:12.919960Z",
     "start_time": "2023-03-14T08:43:12.547540Z"
    },
    "executionInfo": {
     "elapsed": 4630,
     "status": "ok",
     "timestamp": 1678785161112,
     "user": {
      "displayName": "encore엔코아",
      "userId": "03488190351334320755"
     },
     "user_tz": -540
    },
    "id": "jF_VYbhnmLOu"
   },
   "outputs": [],
   "source": [
    "# 판별자 생성 + 컴파일\n",
    "discriminator = create_discriminator(img_shape) #(28, 28, 1)\n",
    "discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 생성자 생성\n",
    "generator = create_generator(z_dim)\n",
    "discriminator.trainable=False  # GAN 모델의 discriminator(layer)를 Frozen(학습할때 weight가 update되지 않게함.)\n",
    "\n",
    "# GAN 모델 생성\n",
    "gan = create_gan(generator, discriminator)\n",
    "gan.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TMlEwi81mLOx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cv5f8WbtsifV"
   },
   "source": [
    "# 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T08:46:50.702366Z",
     "start_time": "2023-03-14T08:46:50.690445Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1678785163578,
     "user": {
      "displayName": "encore엔코아",
      "userId": "03488190351334320755"
     },
     "user_tz": -540
    },
    "id": "OSnHOPy5zf7Q"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def sample_images(generator, image_grid_row=4, image_grid_col=4):\n",
    "    \"\"\"\n",
    "    Generator를 이용해 가짜 이미지를 생성해 그리는 함수.\n",
    "    그리드 행, 열의 개수를 받아 행 * 열 개수만큼 그린다.\n",
    "    [매개변수]\n",
    "        generator: Generator 모델\n",
    "        image_grid_rows: 이미지를 그릴 grid 행수 (기본값 : 4)\n",
    "        image_grid_columns: 이미지를 그릴 grid 열수(기본값 : 4)\n",
    "    \"\"\"\n",
    "    z = np.random.normal(0, 1, (image_grid_row*image_grid_col, z_dim))\n",
    "    gen_images = generator.predict(z)\n",
    "    plt.figure(figsize=(7,7))\n",
    "    for i in range(image_grid_row * image_grid_col):\n",
    "        plt.subplot(image_grid_row, image_grid_col, i+1)\n",
    "        plt.imshow(gen_images[i, :, :, 0], cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T08:46:55.705920Z",
     "start_time": "2023-03-14T08:46:55.048458Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "executionInfo": {
     "elapsed": 10158,
     "status": "ok",
     "timestamp": 1678785174266,
     "user": {
      "displayName": "encore엔코아",
      "userId": "03488190351334320755"
     },
     "user_tz": -540
    },
    "id": "t22DA0_0mLO3",
    "outputId": "4e9208c3-5b25-41a2-f766-85a68413e566"
   },
   "outputs": [],
   "source": [
    "sample_images(generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XiYFGL_XYysy"
   },
   "source": [
    "## training 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T09:06:54.859120Z",
     "start_time": "2023-03-14T09:06:54.826004Z"
    },
    "executionInfo": {
     "elapsed": 504,
     "status": "ok",
     "timestamp": 1678785180976,
     "user": {
      "displayName": "encore엔코아",
      "userId": "03488190351334320755"
     },
     "user_tz": -540
    },
    "id": "vdszFNIYmLO5"
   },
   "outputs": [],
   "source": [
    "loss_list = []\n",
    "acc_list = []\n",
    "iteration_list = []\n",
    "def train(train_image, iterations, batch_size, sample_interval):\n",
    "\"\"\"\n",
    "    [parameter]\n",
    "        train_image: 진짜 이미지데이터셋\n",
    "        iterations : 총 step수\n",
    "        batch_size : batch size\n",
    "        sample_interval: 몇 iteration당 한번씩 훈결결과를 출력할지 \n",
    "\"\"\"    \n",
    "\n",
    "    train_image = train_image/127.5-1 # -1 ~ 1사이로 scaling   # 전처리\n",
    "    train_image = train_image[..., np.newaxis] #채널 차원 증가. (28, 28) => (28, 28, 1)\n",
    "\n",
    "    # Label 생성: fake-0, real: 1\n",
    "    real = np.ones((batch_size, 1))\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "\n",
    "    # 학습.\n",
    "    for iteration in range(iterations):\n",
    "        #################################### 판별자 훈련\n",
    "        # 정답에서 추출할 이미지의 index를 random 함수를 이용해 batch 개수만큼 조회\n",
    "        idx = np.random.randint(0, train_image.shape[0], batch_size)\n",
    "        # 학습에 사용할 정답 이미지들 조회\n",
    "        real_imgs = train_image[idx]\n",
    "        \n",
    "        # Fake image를 만들기 위해 generator에 넣어줄 잡음 생성.\n",
    "        z = np.random.normal(0,1, (batch_size, 100))\n",
    "        # Generator를 이용해 Fake image 생성\n",
    "        gen_imgs = generator.predict(z)\n",
    "        \n",
    "        #진짜 이미지로 학습\n",
    "        d_loss_acc_real = discriminator.train_on_batch(real_imgs, real)  # 한스텝 학습시키는 메소드\n",
    "        #생성자가 만든 가짜 이미지로 학습\n",
    "        d_loss_acc_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
    "\n",
    "        d_loss, acc = np.add(d_loss_acc_real, d_loss_acc_fake)*0.5\n",
    "\n",
    "        ####################################생성자 훈련 - gan을 이용해서 훈련.\n",
    "        z = np.random.normal(0, 1, (batch_size, 100))\n",
    "        gan_loss = gan.train_on_batch(z, real) # input으로 잡음과 정답을 전달\n",
    "\n",
    "        # 중간결과 확인\n",
    "        if iteration % sample_interval == 0:\n",
    "            loss_list.append((d_loss, gan_loss))\n",
    "            acc_list.append(acc)\n",
    "            iteration_list.append(iteration)\n",
    "            print(f'판별자 손실:{d_loss}, 판별자정확도:{acc}, gan 손실:{gan_loss}')\n",
    "            sample_images(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T09:08:42.006182Z",
     "start_time": "2023-03-14T09:07:24.082871Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1XlF5qkSny30PnnW-zJcGEzP7g9FJKSr9"
    },
    "executionInfo": {
     "elapsed": 1601189,
     "status": "ok",
     "timestamp": 1678786802296,
     "user": {
      "displayName": "encore엔코아",
      "userId": "03488190351334320755"
     },
     "user_tz": -540
    },
    "id": "ZvW2z7EemLO7",
    "outputId": "ff9245bb-ab5d-4962-fe63-9347a77e9509",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "iterations = 10000\n",
    "batch_size=100\n",
    "sample_interval=500\n",
    "start = time.time()\n",
    "\n",
    "train(X_train, iterations, batch_size, sample_interval)\n",
    "\n",
    "end = time.time()\n",
    "print((end-start)/60, '분')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1768,
     "status": "ok",
     "timestamp": 1678786805942,
     "user": {
      "displayName": "encore엔코아",
      "userId": "03488190351334320755"
     },
     "user_tz": -540
    },
    "id": "Aw_UXPz6Yysy",
    "outputId": "5e7a6243-a936-4fab-ab6c-6da40e4f1314"
   },
   "outputs": [],
   "source": [
    "save_path = '/content/drive/MyDrive/saved_model/fashion_mnist_gan'\n",
    "generator.save(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VRn6bzVDYysy"
   },
   "source": [
    "# 이미지 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 684,
     "status": "ok",
     "timestamp": 1678787409872,
     "user": {
      "displayName": "encore엔코아",
      "userId": "03488190351334320755"
     },
     "user_tz": -540
    },
    "id": "TUK4dEY2hkP8",
    "outputId": "02d12882-ec73-454c-c9c3-db917f0d38cb"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "save_path = '/content/drive/MyDrive/saved_model/fashion_mnist_gan'\n",
    "saved_generator = tf.keras.models.load_model(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 881,
     "status": "ok",
     "timestamp": 1678787437235,
     "user": {
      "displayName": "encore엔코아",
      "userId": "03488190351334320755"
     },
     "user_tz": -540
    },
    "id": "iz0l3ZujmLPE",
    "outputId": "e77a5465-1f23-480b-c8ce-9827bf394aed"
   },
   "outputs": [],
   "source": [
    "z = np.random.normal(0, 1, (3, 100)) \n",
    "pred = saved_generator.predict(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1678787440070,
     "user": {
      "displayName": "encore엔코아",
      "userId": "03488190351334320755"
     },
     "user_tz": -540
    },
    "id": "uW8kPixnmLPG",
    "outputId": "361c87c9-eb6f-4483-ef75-1e8b33708348"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.imshow(pred[i].reshape(28,28), cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "924EJxm57dJy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
